{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        self.activation_function = lambda x : 1/(1+np.exp(-x))  # \n",
    "        \n",
    "#def sigmoid(self,x): return 1//1+np.exp(-x)\n",
    "                       \n",
    "\n",
    "    def train(self, features, targets):\n",
    "        ''' Train the network on batch of features and targets. \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            \n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "        \n",
    "        '''\n",
    "        n_records = features.shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        for X, y in zip(features, targets):\n",
    "            \n",
    "            final_outputs, hidden_outputs = self.forward_pass_train(X)  # Implement the forward pass function below\n",
    "            # Implement the backproagation function below\n",
    "            delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y, \n",
    "                                                                        delta_weights_i_h, delta_weights_h_o)\n",
    "        self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n",
    "\n",
    "\n",
    "    def forward_pass_train(self, X):\n",
    "        ''' Implement forward pass here \n",
    "         \n",
    "            Arguments\n",
    "            ---------\n",
    "            X: features batch\n",
    "        '''\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ##      \n",
    "        \n",
    "        # TODO: Hidden layer - Replace these values with your calculations.\n",
    "        hidden_inputs =np.dot(X, self.weights_input_to_hidden) #X.dot(self.weights_input_to_hidden) # signals into hidden layer  np.dot(X, weight)??np.dot(X, weights_input_to_hidden)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "        #print('hidden_inputs', hidden_inputs.shape)\n",
    "        #print('hidden_outputs', hidden_outputs.shape)\n",
    "        # TODO: Output layer - Replace these values with your calculations.\n",
    "        final_inputs =  np.dot(hidden_outputs, self.weights_hidden_to_output)  #(hidden_outputs.dot(self.weights_hidden_to_output)) # signals into final output layer  np.dot(hidden_outputs, weights_hidden_to_output)\n",
    "        final_outputs = (final_inputs) # signals from final output layer, not activation function here\n",
    "        #print('final_inputs', final_inputs.shape)\n",
    "        #print('final_outputs', final_outputs.shape)\n",
    "        return final_outputs, hidden_outputs\n",
    "\n",
    "    def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n",
    "        ''' Implement backpropagation\n",
    "         \n",
    "            Arguments\n",
    "            ---------\n",
    "            final_outputs: output from forward pass\n",
    "            y: target (i.e. label) batch\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "        '''\n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "\n",
    "        # TODO: Output error - Replace this value with your calculations.\n",
    "       \n",
    "        error = y - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "            #print('error',error.shape)\n",
    "            #print('output_error_term', final_outputs.shape)\n",
    "        output_error_term = error #?* final_outputs * (1- final_outputs)\n",
    "            #print('output_error_term', output_error_term.shape)\n",
    "            # TODO: Calculate the hidden layer's contribution to the error\n",
    "            #hidden_error = error *  self.activation_function(final_outputs)  #self.sigmoid\n",
    "            #print('innan hidden_error', self.weights_hidden_to_output.shape, self.weights_hidden_to_output.T.shape, output_error_term.shape )\n",
    "        hidden_error = np.dot (self.weights_hidden_to_output,output_error_term,)  #switched positions and transposed\n",
    "            #hidden_error = output_error_term.dot(self.weights_hidden_to_output.T)\n",
    "            #print('hidden_error', hidden_error.shape)\n",
    "            # TODO: Backpropagated error terms - Replace these values with your calculations.\n",
    "            #print(' innan Hidden_error_term', hidden_error.shape, hidden_outputs.shape, hidden_outputs[:,None].shape)\n",
    "        #hidden_error_term = np.dot(self.weights_hidden_to_output , output_error_term)* hidden_outputs * (1 - hidden_outputs)\n",
    "        hidden_error_term = hidden_error * hidden_outputs * (1- hidden_outputs)\n",
    "            #print('efter hidden_error_term', hidden_error_term.shape)\n",
    "            #hidden_error_term = output_error_term.dot(self.weights_input_to_hidden.T)\n",
    "        \n",
    "            # TODO: Add Weight step (input to hidden) and Weight step (hidden to output).\n",
    "            # Weight step (input to hidden)\n",
    "            #print('innan delta_w', hidden_error_term.shape, X[:,None].shape)\n",
    "        delta_weights_i_h += hidden_error_term * X[:,None] \n",
    "            #print('efter delta_w_i_h', delta_weights_i_h.shape)\n",
    "            # Weight step (hidden to output)\n",
    "            #print('innan delta_w_h_o', output_error_term.shape, hidden_outputs.shape)\n",
    "        delta_weights_h_o += output_error_term * hidden_outputs[:,None]  \n",
    "\n",
    "        #print('delta_w', delta_weights_i_h.shape, delta_weights_h_o.shape)\n",
    "        \n",
    "        return delta_weights_i_h, delta_weights_h_o\n",
    "\n",
    "    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        ''' Update weights on gradient descent step\n",
    "         \n",
    "            Arguments\n",
    "            ---------\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "            n_records: number of records\n",
    "        '''\n",
    "        self.weights_hidden_to_output += self.lr * delta_weights_h_o / n_records # update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += self.lr * delta_weights_i_h /n_records # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features \n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "        \n",
    "            #### Implement the forward pass here ####\n",
    "            # TODO: Hidden layer - replace these values with the appropriate calculations.\n",
    "            #print('Test_h_inputs', features.shape, self.weights_input_to_hidden.shape)\n",
    "        hidden_inputs = features.dot(self.weights_input_to_hidden) # signals into hidden layer\n",
    "            #print('Test_h_outputs', hidden_inputs.shape)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)   # sigma(hidden_inputs) # signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer - Replace these values with the appropriate calculations.\n",
    "            #print('Test_final_out',hidden_outputs.shape)\n",
    "        final_inputs =  (hidden_outputs.dot(self.weights_hidden_to_output)) # signals into final output layer\n",
    "            #print('Test_final', final_inputs.shape)\n",
    "        final_outputs = (final_inputs) # signals from final output layer \n",
    "        \n",
    "        return final_outputs\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Set your hyperparameters here\n",
    "##########################################################\n",
    "iterations = 5000\n",
    "learning_rate = 0.6 #0.009 #0.001 \n",
    "hidden_nodes = 8\n",
    "output_nodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
